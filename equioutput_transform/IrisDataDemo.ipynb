{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nimport numpy as np\\nimport random\\nimport math\\nimport sys\\n\\nwith open(\"irisTrainData.txt\", \"r\") as filestream:\\n    with open(\"irisTrainDataNew.txt\", \"w\") as filestreamtwo :\\n        for line in filestream:\\n            currentline = line.split(\",\")\\n           # total = currentline[0] + currentline[1] + currentline + \"\\n\"\\n            str1 = (currentline[1] + \\',\\' + currentline[2]+ \\',\\' + currentline[3]+ \\',\\' + currentline[4]+ \\',\\' + currentline[5] + \\',\\' + \\n                 currentline[6])\\n            filestreamtwo.write(str1)\\n\\nwith open(\"irisTestData.txt\", \"r\") as filestreamTest:\\n    with open(\"irisTestDataNew.txt\", \"w\") as filestreamTesttwo :\\n        for line in filestreamTest:\\n            currentline = line.split(\",\")\\n           # total = currentline[0] + currentline[1] + currentline + \"\\n\"\\n            str1 = (currentline[1] + \\',\\' + currentline[2]+ \\',\\' + currentline[3]+ \\',\\' + currentline[4]+ \\',\\' + currentline[5] + \\',\\' + \\n                 currentline[6])\\n            filestreamTesttwo.write(str1)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "\n",
    "with open(\"irisTrainData.txt\", \"r\") as filestream:\n",
    "    with open(\"irisTrainDataNew.txt\", \"w\") as filestreamtwo :\n",
    "        for line in filestream:\n",
    "            currentline = line.split(\",\")\n",
    "           # total = currentline[0] + currentline[1] + currentline + \"\\n\"\n",
    "            str1 = (currentline[1] + ',' + currentline[2]+ ',' + currentline[3]+ ',' + currentline[4]+ ',' + currentline[5] + ',' + \n",
    "                 currentline[6])\n",
    "            filestreamtwo.write(str1)\n",
    "\n",
    "with open(\"irisTestData.txt\", \"r\") as filestreamTest:\n",
    "    with open(\"irisTestDataNew.txt\", \"w\") as filestreamTesttwo :\n",
    "        for line in filestreamTest:\n",
    "            currentline = line.split(\",\")\n",
    "           # total = currentline[0] + currentline[1] + currentline + \"\\n\"\n",
    "            str1 = (currentline[1] + ',' + currentline[2]+ ',' + currentline[3]+ ',' + currentline[4]+ ',' + currentline[5] + ',' + \n",
    "                 currentline[6])\n",
    "            filestreamTesttwo.write(str1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np \\nmu, sigma = 0, 0.1 \\n# creating a noise with the same dimension as the dataset (2,2) \\nnoise = np.random.normal(mu, sigma, [30,7]) \\nprint(noise)\\n\\n\"\"\"\\nprint output: \\narray([[-0.11114313,  0.25927152],\\n       [ 0.06701506, -0.09364186]])\\n\"\"\"\\nclean_signal = testDataMatrix\\nsignal = clean_signal + noise\\nprint(signal)\\ntestmatrixWithNoise = signal\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding noise\n",
    "'''\n",
    "import numpy as np \n",
    "mu, sigma = 0, 0.1 \n",
    "# creating a noise with the same dimension as the dataset (2,2) \n",
    "noise = np.random.normal(mu, sigma, [30,7]) \n",
    "print(noise)\n",
    "\n",
    "\"\"\"\n",
    "print output: \n",
    "array([[-0.11114313,  0.25927152],\n",
    "       [ 0.06701506, -0.09364186]])\n",
    "\"\"\"\n",
    "clean_signal = testDataMatrix\n",
    "signal = clean_signal + noise\n",
    "print(signal)\n",
    "testmatrixWithNoise = signal\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "\n",
    "#consider 10 items in training and test \n",
    "with open(\"irisTrainData.txt\", \"r\") as filestream:\n",
    "    with open(\"irisTrainDataNew2.txt\", \"w\") as filestreamtwo :\n",
    "        for line in filestream:\n",
    "            currentline = line.split(\",\")\n",
    "           # total = currentline[0] + currentline[1] + currentline + \"\\n\"\n",
    "            \n",
    "            \n",
    "            str1 = (currentline[0] + ',' + currentline[1]+ ',' + currentline[2]+ ',' + currentline[3]+\n",
    "                    ',' + currentline[0] + ',' + currentline[1]+ ',' + currentline[2]+\n",
    "                    ',' + currentline[4] + ',' +  currentline[5] +',' + currentline[6])\n",
    "            str1 = (currentline[0] + ',' + currentline[1]+ ','  +  currentline[5] +',' + currentline[6])\n",
    "            \n",
    "            \n",
    "            filestreamtwo.write(str1)\n",
    "           \n",
    "\n",
    "with open(\"irisTestData.txt\", \"r\") as filestreamTest:\n",
    "    with open(\"irisTestDataNew2.txt\", \"w\") as filestreamTesttwo :\n",
    "        for line in filestreamTest:\n",
    "            currentline = line.split(\",\")\n",
    "            # total = currentline[0] + currentline[1] + currentline + \"\\n\"\n",
    "            str1 = (currentline[0] + ',' + currentline[1]+ ','  +  currentline[5] +',' + currentline[6])\n",
    "            \n",
    "            filestreamTesttwo.write(str1)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin NN back-propagation demo \n",
      "\n",
      "Using Python version 3.6.4 |Anaconda, Inc.| (default, Mar 12 2018, 20:20:50) [MSC v.1900 64 bit (AMD64)]\n",
      " and NumPy version 1.16.2\n",
      "\n",
      "Creating a 4-50-3 neural network \n",
      "\n",
      "Loading Iris training and test data \n",
      "\n",
      "Test data: \n",
      "[  0]  5.1   3.5   1.4   0.2   1.0   0.0   0.0  \n",
      "[  1]  4.9   3.0   1.4   0.2   1.0   0.0   0.0  \n",
      "[  2]  4.7   3.2   1.3   0.2   1.0   0.0   0.0  \n",
      "[  3]  4.6   3.1   1.5   0.2   1.0   0.0   0.0  \n",
      " . . . \n",
      "[119]  6.9   3.1   5.4   2.1   0.0   0.0   1.0  \n",
      "\n",
      "Setting maxEpochs = 50\n",
      "Setting learning rate = 0.010 \n",
      "\n",
      "Starting training\n",
      "inside train\n",
      "epoch = 10 ms error = 0.6030 \n",
      "epoch = 20 ms error = 0.3297 \n",
      "epoch = 30 ms error = 0.2652 \n",
      "epoch = 40 ms error = 0.1986 \n",
      "epoch = 50 ms error = 0.1514 \n",
      "Training complete\n",
      "res sh (403,)\n",
      "ihW sh (4, 50)\n",
      "hoW sh (50, 3)\n",
      "ihW [[-7.41325244e-02  2.65321899e-02  6.83007985e-02 -1.38492426e-02\n",
      "   1.13626570e-02 -6.21924475e-02 -3.34476829e-02  4.56529520e-02\n",
      "   1.01948582e-01  1.07460119e-01 -5.50385043e-02 -5.10007329e-02\n",
      "   5.79805449e-02  1.87815011e-01 -7.34286532e-02  2.42204703e-02\n",
      "   1.75761998e-01 -3.43908854e-02  8.69224817e-02  6.97248429e-02\n",
      "  -9.04737711e-02 -9.01791360e-03  4.49149013e-02  4.25573513e-02\n",
      "  -4.40769345e-02  2.67838407e-02  1.08773254e-01 -7.09875152e-02\n",
      "   1.19626047e-02 -1.06605381e-01 -3.83514836e-02  5.68231046e-02\n",
      "   3.22427824e-02  4.28691246e-02  1.94848165e-01  1.17213883e-01\n",
      "   3.97135578e-02 -1.25427946e-01 -1.14317566e-01 -1.76375564e-02\n",
      "  -1.35981396e-01  1.43933177e-01 -3.72230075e-02 -1.31491676e-01\n",
      "   1.58015057e-04  1.05141588e-02  7.58627290e-03  1.10773914e-01\n",
      "   1.38140291e-01  3.57860848e-02]\n",
      " [-1.03441820e-01  1.42938900e-03  1.32641628e-01 -1.55182285e-02\n",
      "  -5.63374674e-03 -8.72495025e-02  4.64150459e-02  5.96867912e-02\n",
      "   1.52610227e-01  1.61409602e-01 -1.17056571e-01 -1.04294777e-01\n",
      "   7.16267899e-02  2.43571863e-01 -1.45939112e-01  5.16886935e-02\n",
      "   2.26822063e-01  3.56289856e-02  1.36467025e-01  9.63726714e-02\n",
      "  -1.58214405e-01  7.67289661e-03 -3.83545458e-02 -2.98035573e-02\n",
      "   3.57041471e-02  1.04894482e-01  1.33959711e-01 -9.86089837e-03\n",
      "   5.59353419e-02 -1.59989640e-01 -8.98311660e-02  6.79991618e-02\n",
      "  -3.78166325e-02  8.34777579e-02  2.43847549e-01  1.91273727e-02\n",
      "   1.31808417e-02 -1.58359632e-01 -4.84367311e-02  6.10362031e-02\n",
      "  -1.95280477e-01  1.80928379e-01 -4.20435369e-02 -1.48651138e-01\n",
      "  -8.29235092e-02  7.29950964e-02  5.69431111e-02  1.34462893e-01\n",
      "   1.60073757e-01 -2.73004193e-02]\n",
      " [ 1.69708818e-01  6.56353086e-02 -2.00393364e-01  5.43398894e-02\n",
      "   4.58688885e-02  1.34827077e-01 -1.24149419e-01 -7.58372545e-02\n",
      "  -2.18616590e-01 -2.36696482e-01  1.95316389e-01  1.72293156e-01\n",
      "  -8.71943533e-02 -3.43679488e-01  2.19214112e-01 -1.07056066e-01\n",
      "  -3.24624568e-01 -1.22546449e-01 -2.18335062e-01 -1.59246817e-01\n",
      "   2.30794549e-01 -3.55129428e-02  1.51438341e-01  1.39166504e-01\n",
      "  -1.16685368e-01 -1.99203879e-01 -2.10846707e-01 -1.19318672e-01\n",
      "  -1.14509992e-01  2.31701508e-01  1.69514239e-01 -9.88079309e-02\n",
      "   1.46377087e-01 -1.34374902e-01 -3.47661048e-01  1.00953750e-01\n",
      "   1.04227532e-02  2.28541926e-01 -6.93185776e-02 -1.60884202e-01\n",
      "   2.76869655e-01 -2.73605943e-01  2.33789627e-02  2.33847171e-01\n",
      "   1.73954725e-01 -1.36291116e-01 -1.01214521e-01 -2.06520885e-01\n",
      "  -2.41151571e-01  1.13526054e-01]\n",
      " [ 9.77945626e-02  1.90570336e-02 -1.12989150e-01  2.68851630e-02\n",
      "   2.30688136e-02  7.62513801e-02 -4.53119650e-02 -5.49575351e-02\n",
      "  -1.28597617e-01 -1.30873427e-01  1.05750963e-01  9.14768279e-02\n",
      "  -5.81765212e-02 -2.06662238e-01  1.17937423e-01 -6.50785044e-02\n",
      "  -1.83490619e-01 -4.48198356e-02 -1.27039328e-01 -9.32017341e-02\n",
      "   1.29940197e-01 -1.33899832e-02  6.98685348e-02  5.59269413e-02\n",
      "  -5.59368953e-02 -1.03928246e-01 -1.14818834e-01 -4.54047620e-02\n",
      "  -6.13409542e-02  1.27627477e-01  8.92828330e-02 -6.26425594e-02\n",
      "   7.08290860e-02 -7.72927776e-02 -2.17233717e-01  4.03967947e-02\n",
      "   6.47039199e-03  1.46761566e-01 -1.42426360e-02 -6.15917034e-02\n",
      "   1.66228130e-01 -1.62771851e-01  2.29747817e-02  1.46859989e-01\n",
      "   8.48504156e-02 -6.31868020e-02 -5.78964800e-02 -1.24924839e-01\n",
      "  -1.51368082e-01  4.18019667e-02]]\n",
      "hoW [[-0.15799192  0.00758743  0.18358983]\n",
      " [-0.02675555  0.05670098  0.04477788]\n",
      " [ 0.1890398  -0.04958735 -0.2222285 ]\n",
      " [-0.03478646  0.00614585  0.05538265]\n",
      " [-0.02599399  0.03184037  0.03605673]\n",
      " [-0.12304983 -0.01304379  0.14361338]\n",
      " [ 0.08875411 -0.0959836  -0.08215179]\n",
      " [ 0.07586619  0.02919671 -0.08733588]\n",
      " [ 0.20926099  0.00389098 -0.25478807]\n",
      " [ 0.22706784 -0.01396393 -0.2734356 ]\n",
      " [-0.18193316  0.0690124   0.2026082 ]\n",
      " [-0.15095845  0.04885973  0.18290624]\n",
      " [ 0.09553671  0.03875125 -0.09207425]\n",
      " [ 0.3557313   0.03505064 -0.42151657]\n",
      " [-0.21339358  0.06395156  0.23503721]\n",
      " [ 0.08785822 -0.02713049 -0.11104778]\n",
      " [ 0.31963548  0.04266861 -0.3900639 ]\n",
      " [ 0.07746013 -0.10000378 -0.08095209]\n",
      " [ 0.20524012 -0.05100067 -0.24819987]\n",
      " [ 0.1344067  -0.00494615 -0.18147144]\n",
      " [-0.23665473  0.04336906  0.2526428 ]\n",
      " [ 0.02453953 -0.0199187  -0.02709213]\n",
      " [-0.08557427  0.14785285  0.09902831]\n",
      " [-0.08333867  0.12881635  0.08075537]\n",
      " [ 0.07889873 -0.10710254 -0.07184064]\n",
      " [ 0.17050013 -0.11895293 -0.18304852]\n",
      " [ 0.18884172  0.02239914 -0.23836301]\n",
      " [ 0.04244706 -0.1446828  -0.0498443 ]\n",
      " [ 0.09239365 -0.04693325 -0.10759319]\n",
      " [-0.22375825  0.00698477  0.2641901 ]\n",
      " [-0.14059609  0.0715266   0.17309362]\n",
      " [ 0.08711779  0.0317103  -0.11257366]\n",
      " [-0.08925755  0.13109691  0.10028872]\n",
      " [ 0.12238768 -0.02056699 -0.13851574]\n",
      " [ 0.3536367   0.04717939 -0.4348395 ]\n",
      " [-0.01871852  0.17661236  0.00837395]\n",
      " [ 0.00126349  0.04183186 -0.00152584]\n",
      " [-0.21882202 -0.04628782  0.26827154]\n",
      " [-0.01125953 -0.15206374  0.01282716]\n",
      " [ 0.1181016  -0.11780249 -0.11150847]\n",
      " [-0.27929112  0.00781348  0.33394796]\n",
      " [ 0.25747532  0.00700326 -0.33367926]\n",
      " [-0.04104608 -0.03574242  0.0328456 ]\n",
      " [-0.21216272 -0.04115048  0.27945855]\n",
      " [-0.14343113  0.11491437  0.1405324 ]\n",
      " [ 0.1158802  -0.06243579 -0.11926892]\n",
      " [ 0.08583108 -0.03820036 -0.09702009]\n",
      " [ 0.18871792  0.02725462 -0.23879836]\n",
      " [ 0.22287743  0.06258046 -0.2838698 ]\n",
      " [-0.06422612  0.09785768  0.07699971]]\n",
      "\n",
      "Accuracy on 120-item train data = 0.9500 \n",
      "Accuracy on 30-item test data   = 0.9667 \n",
      "\n",
      "End demo \n",
      "\n",
      "ihWeights:\n",
      "hoWeights:\n",
      "Case 1 : Sign Flip Starts \n",
      "ihWeightsSignChanged:\n",
      "[[ 7.41325244e-02 -2.65321899e-02 -6.83007985e-02  1.38492426e-02\n",
      "  -1.13626570e-02  6.21924475e-02  3.34476829e-02 -4.56529520e-02\n",
      "  -1.01948582e-01 -1.07460119e-01  5.50385043e-02  5.10007329e-02\n",
      "  -5.79805449e-02 -1.87815011e-01  7.34286532e-02 -2.42204703e-02\n",
      "  -1.75761998e-01  3.43908854e-02 -8.69224817e-02 -6.97248429e-02\n",
      "   9.04737711e-02  9.01791360e-03 -4.49149013e-02 -4.25573513e-02\n",
      "   4.40769345e-02 -2.67838407e-02 -1.08773254e-01  7.09875152e-02\n",
      "  -1.19626047e-02  1.06605381e-01  3.83514836e-02 -5.68231046e-02\n",
      "  -3.22427824e-02 -4.28691246e-02 -1.94848165e-01 -1.17213883e-01\n",
      "  -3.97135578e-02  1.25427946e-01  1.14317566e-01  1.76375564e-02\n",
      "   1.35981396e-01 -1.43933177e-01  3.72230075e-02  1.31491676e-01\n",
      "  -1.58015057e-04 -1.05141588e-02 -7.58627290e-03 -1.10773914e-01\n",
      "  -1.38140291e-01 -3.57860848e-02]\n",
      " [ 1.03441820e-01 -1.42938900e-03 -1.32641628e-01  1.55182285e-02\n",
      "   5.63374674e-03  8.72495025e-02 -4.64150459e-02 -5.96867912e-02\n",
      "  -1.52610227e-01 -1.61409602e-01  1.17056571e-01  1.04294777e-01\n",
      "  -7.16267899e-02 -2.43571863e-01  1.45939112e-01 -5.16886935e-02\n",
      "  -2.26822063e-01 -3.56289856e-02 -1.36467025e-01 -9.63726714e-02\n",
      "   1.58214405e-01 -7.67289661e-03  3.83545458e-02  2.98035573e-02\n",
      "  -3.57041471e-02 -1.04894482e-01 -1.33959711e-01  9.86089837e-03\n",
      "  -5.59353419e-02  1.59989640e-01  8.98311660e-02 -6.79991618e-02\n",
      "   3.78166325e-02 -8.34777579e-02 -2.43847549e-01 -1.91273727e-02\n",
      "  -1.31808417e-02  1.58359632e-01  4.84367311e-02 -6.10362031e-02\n",
      "   1.95280477e-01 -1.80928379e-01  4.20435369e-02  1.48651138e-01\n",
      "   8.29235092e-02 -7.29950964e-02 -5.69431111e-02 -1.34462893e-01\n",
      "  -1.60073757e-01  2.73004193e-02]\n",
      " [-1.69708818e-01 -6.56353086e-02  2.00393364e-01 -5.43398894e-02\n",
      "  -4.58688885e-02 -1.34827077e-01  1.24149419e-01  7.58372545e-02\n",
      "   2.18616590e-01  2.36696482e-01 -1.95316389e-01 -1.72293156e-01\n",
      "   8.71943533e-02  3.43679488e-01 -2.19214112e-01  1.07056066e-01\n",
      "   3.24624568e-01  1.22546449e-01  2.18335062e-01  1.59246817e-01\n",
      "  -2.30794549e-01  3.55129428e-02 -1.51438341e-01 -1.39166504e-01\n",
      "   1.16685368e-01  1.99203879e-01  2.10846707e-01  1.19318672e-01\n",
      "   1.14509992e-01 -2.31701508e-01 -1.69514239e-01  9.88079309e-02\n",
      "  -1.46377087e-01  1.34374902e-01  3.47661048e-01 -1.00953750e-01\n",
      "  -1.04227532e-02 -2.28541926e-01  6.93185776e-02  1.60884202e-01\n",
      "  -2.76869655e-01  2.73605943e-01 -2.33789627e-02 -2.33847171e-01\n",
      "  -1.73954725e-01  1.36291116e-01  1.01214521e-01  2.06520885e-01\n",
      "   2.41151571e-01 -1.13526054e-01]\n",
      " [-9.77945626e-02 -1.90570336e-02  1.12989150e-01 -2.68851630e-02\n",
      "  -2.30688136e-02 -7.62513801e-02  4.53119650e-02  5.49575351e-02\n",
      "   1.28597617e-01  1.30873427e-01 -1.05750963e-01 -9.14768279e-02\n",
      "   5.81765212e-02  2.06662238e-01 -1.17937423e-01  6.50785044e-02\n",
      "   1.83490619e-01  4.48198356e-02  1.27039328e-01  9.32017341e-02\n",
      "  -1.29940197e-01  1.33899832e-02 -6.98685348e-02 -5.59269413e-02\n",
      "   5.59368953e-02  1.03928246e-01  1.14818834e-01  4.54047620e-02\n",
      "   6.13409542e-02 -1.27627477e-01 -8.92828330e-02  6.26425594e-02\n",
      "  -7.08290860e-02  7.72927776e-02  2.17233717e-01 -4.03967947e-02\n",
      "  -6.47039199e-03 -1.46761566e-01  1.42426360e-02  6.15917034e-02\n",
      "  -1.66228130e-01  1.62771851e-01 -2.29747817e-02 -1.46859989e-01\n",
      "  -8.48504156e-02  6.31868020e-02  5.78964800e-02  1.24924839e-01\n",
      "   1.51368082e-01 -4.18019667e-02]]\n",
      "hoWeightsSignChanged:\n",
      "[[ 0.15799192 -0.00758743 -0.18358983]\n",
      " [ 0.02675555 -0.05670098 -0.04477788]\n",
      " [-0.1890398   0.04958735  0.2222285 ]\n",
      " [ 0.03478646 -0.00614585 -0.05538265]\n",
      " [ 0.02599399 -0.03184037 -0.03605673]\n",
      " [ 0.12304983  0.01304379 -0.14361338]\n",
      " [-0.08875411  0.0959836   0.08215179]\n",
      " [-0.07586619 -0.02919671  0.08733588]\n",
      " [-0.20926099 -0.00389098  0.25478807]\n",
      " [-0.22706784  0.01396393  0.2734356 ]\n",
      " [ 0.18193316 -0.0690124  -0.2026082 ]\n",
      " [ 0.15095845 -0.04885973 -0.18290624]\n",
      " [-0.09553671 -0.03875125  0.09207425]\n",
      " [-0.3557313  -0.03505064  0.42151657]\n",
      " [ 0.21339358 -0.06395156 -0.23503721]\n",
      " [-0.08785822  0.02713049  0.11104778]\n",
      " [-0.31963548 -0.04266861  0.3900639 ]\n",
      " [-0.07746013  0.10000378  0.08095209]\n",
      " [-0.20524012  0.05100067  0.24819987]\n",
      " [-0.1344067   0.00494615  0.18147144]\n",
      " [ 0.23665473 -0.04336906 -0.2526428 ]\n",
      " [-0.02453953  0.0199187   0.02709213]\n",
      " [ 0.08557427 -0.14785285 -0.09902831]\n",
      " [ 0.08333867 -0.12881635 -0.08075537]\n",
      " [-0.07889873  0.10710254  0.07184064]\n",
      " [-0.17050013  0.11895293  0.18304852]\n",
      " [-0.18884172 -0.02239914  0.23836301]\n",
      " [-0.04244706  0.1446828   0.0498443 ]\n",
      " [-0.09239365  0.04693325  0.10759319]\n",
      " [ 0.22375825 -0.00698477 -0.2641901 ]\n",
      " [ 0.14059609 -0.0715266  -0.17309362]\n",
      " [-0.08711779 -0.0317103   0.11257366]\n",
      " [ 0.08925755 -0.13109691 -0.10028872]\n",
      " [-0.12238768  0.02056699  0.13851574]\n",
      " [-0.3536367  -0.04717939  0.4348395 ]\n",
      " [ 0.01871852 -0.17661236 -0.00837395]\n",
      " [-0.00126349 -0.04183186  0.00152584]\n",
      " [ 0.21882202  0.04628782 -0.26827154]\n",
      " [ 0.01125953  0.15206374 -0.01282716]\n",
      " [-0.1181016   0.11780249  0.11150847]\n",
      " [ 0.27929112 -0.00781348 -0.33394796]\n",
      " [-0.25747532 -0.00700326  0.33367926]\n",
      " [ 0.04104608  0.03574242 -0.0328456 ]\n",
      " [ 0.21216272  0.04115048 -0.27945855]\n",
      " [ 0.14343113 -0.11491437 -0.1405324 ]\n",
      " [-0.1158802   0.06243579  0.11926892]\n",
      " [-0.08583108  0.03820036  0.09702009]\n",
      " [-0.18871792 -0.02725462  0.23879836]\n",
      " [-0.22287743 -0.06258046  0.2838698 ]\n",
      " [ 0.06422612 -0.09785768 -0.07699971]]\n",
      "Accuracy with SignFlip  on 30-item test data   = 0.9667 \n",
      "Case 1 : Sign Flip Ends \n",
      "Case 2 : Swap Hidden Weights Starts \n",
      "b==ihW= [[-7.41325244e-02  2.65321899e-02  6.83007985e-02 -1.38492426e-02\n",
      "   1.13626570e-02 -6.21924475e-02 -3.34476829e-02  4.56529520e-02\n",
      "   1.01948582e-01  1.07460119e-01 -5.50385043e-02 -5.10007329e-02\n",
      "   5.79805449e-02  1.87815011e-01 -7.34286532e-02  2.42204703e-02\n",
      "   1.75761998e-01 -3.43908854e-02  8.69224817e-02  6.97248429e-02\n",
      "  -9.04737711e-02 -9.01791360e-03  4.49149013e-02  4.25573513e-02\n",
      "  -4.40769345e-02  2.67838407e-02  1.08773254e-01 -7.09875152e-02\n",
      "   1.19626047e-02 -1.06605381e-01 -3.83514836e-02  5.68231046e-02\n",
      "   3.22427824e-02  4.28691246e-02  1.94848165e-01  1.17213883e-01\n",
      "   3.97135578e-02 -1.25427946e-01 -1.14317566e-01 -1.76375564e-02\n",
      "  -1.35981396e-01  1.43933177e-01 -3.72230075e-02 -1.31491676e-01\n",
      "   1.58015057e-04  1.05141588e-02  7.58627290e-03  1.10773914e-01\n",
      "   1.38140291e-01  3.57860848e-02]\n",
      " [-1.03441820e-01  1.42938900e-03  1.32641628e-01 -1.55182285e-02\n",
      "  -5.63374674e-03 -8.72495025e-02  4.64150459e-02  5.96867912e-02\n",
      "   1.52610227e-01  1.61409602e-01 -1.17056571e-01 -1.04294777e-01\n",
      "   7.16267899e-02  2.43571863e-01 -1.45939112e-01  5.16886935e-02\n",
      "   2.26822063e-01  3.56289856e-02  1.36467025e-01  9.63726714e-02\n",
      "  -1.58214405e-01  7.67289661e-03 -3.83545458e-02 -2.98035573e-02\n",
      "   3.57041471e-02  1.04894482e-01  1.33959711e-01 -9.86089837e-03\n",
      "   5.59353419e-02 -1.59989640e-01 -8.98311660e-02  6.79991618e-02\n",
      "  -3.78166325e-02  8.34777579e-02  2.43847549e-01  1.91273727e-02\n",
      "   1.31808417e-02 -1.58359632e-01 -4.84367311e-02  6.10362031e-02\n",
      "  -1.95280477e-01  1.80928379e-01 -4.20435369e-02 -1.48651138e-01\n",
      "  -8.29235092e-02  7.29950964e-02  5.69431111e-02  1.34462893e-01\n",
      "   1.60073757e-01 -2.73004193e-02]\n",
      " [ 1.69708818e-01  6.56353086e-02 -2.00393364e-01  5.43398894e-02\n",
      "   4.58688885e-02  1.34827077e-01 -1.24149419e-01 -7.58372545e-02\n",
      "  -2.18616590e-01 -2.36696482e-01  1.95316389e-01  1.72293156e-01\n",
      "  -8.71943533e-02 -3.43679488e-01  2.19214112e-01 -1.07056066e-01\n",
      "  -3.24624568e-01 -1.22546449e-01 -2.18335062e-01 -1.59246817e-01\n",
      "   2.30794549e-01 -3.55129428e-02  1.51438341e-01  1.39166504e-01\n",
      "  -1.16685368e-01 -1.99203879e-01 -2.10846707e-01 -1.19318672e-01\n",
      "  -1.14509992e-01  2.31701508e-01  1.69514239e-01 -9.88079309e-02\n",
      "   1.46377087e-01 -1.34374902e-01 -3.47661048e-01  1.00953750e-01\n",
      "   1.04227532e-02  2.28541926e-01 -6.93185776e-02 -1.60884202e-01\n",
      "   2.76869655e-01 -2.73605943e-01  2.33789627e-02  2.33847171e-01\n",
      "   1.73954725e-01 -1.36291116e-01 -1.01214521e-01 -2.06520885e-01\n",
      "  -2.41151571e-01  1.13526054e-01]\n",
      " [ 9.77945626e-02  1.90570336e-02 -1.12989150e-01  2.68851630e-02\n",
      "   2.30688136e-02  7.62513801e-02 -4.53119650e-02 -5.49575351e-02\n",
      "  -1.28597617e-01 -1.30873427e-01  1.05750963e-01  9.14768279e-02\n",
      "  -5.81765212e-02 -2.06662238e-01  1.17937423e-01 -6.50785044e-02\n",
      "  -1.83490619e-01 -4.48198356e-02 -1.27039328e-01 -9.32017341e-02\n",
      "   1.29940197e-01 -1.33899832e-02  6.98685348e-02  5.59269413e-02\n",
      "  -5.59368953e-02 -1.03928246e-01 -1.14818834e-01 -4.54047620e-02\n",
      "  -6.13409542e-02  1.27627477e-01  8.92828330e-02 -6.26425594e-02\n",
      "   7.08290860e-02 -7.72927776e-02 -2.17233717e-01  4.03967947e-02\n",
      "   6.47039199e-03  1.46761566e-01 -1.42426360e-02 -6.15917034e-02\n",
      "   1.66228130e-01 -1.62771851e-01  2.29747817e-02  1.46859989e-01\n",
      "   8.48504156e-02 -6.31868020e-02 -5.78964800e-02 -1.24924839e-01\n",
      "  -1.51368082e-01  4.18019667e-02]]\n",
      "a==hoW= [[-0.15799192  0.00758743  0.18358983]\n",
      " [-0.02675555  0.05670098  0.04477788]\n",
      " [ 0.1890398  -0.04958735 -0.2222285 ]\n",
      " [-0.03478646  0.00614585  0.05538265]\n",
      " [-0.02599399  0.03184037  0.03605673]\n",
      " [-0.12304983 -0.01304379  0.14361338]\n",
      " [ 0.08875411 -0.0959836  -0.08215179]\n",
      " [ 0.07586619  0.02919671 -0.08733588]\n",
      " [ 0.20926099  0.00389098 -0.25478807]\n",
      " [ 0.22706784 -0.01396393 -0.2734356 ]\n",
      " [-0.18193316  0.0690124   0.2026082 ]\n",
      " [-0.15095845  0.04885973  0.18290624]\n",
      " [ 0.09553671  0.03875125 -0.09207425]\n",
      " [ 0.3557313   0.03505064 -0.42151657]\n",
      " [-0.21339358  0.06395156  0.23503721]\n",
      " [ 0.08785822 -0.02713049 -0.11104778]\n",
      " [ 0.31963548  0.04266861 -0.3900639 ]\n",
      " [ 0.07746013 -0.10000378 -0.08095209]\n",
      " [ 0.20524012 -0.05100067 -0.24819987]\n",
      " [ 0.1344067  -0.00494615 -0.18147144]\n",
      " [-0.23665473  0.04336906  0.2526428 ]\n",
      " [ 0.02453953 -0.0199187  -0.02709213]\n",
      " [-0.08557427  0.14785285  0.09902831]\n",
      " [-0.08333867  0.12881635  0.08075537]\n",
      " [ 0.07889873 -0.10710254 -0.07184064]\n",
      " [ 0.17050013 -0.11895293 -0.18304852]\n",
      " [ 0.18884172  0.02239914 -0.23836301]\n",
      " [ 0.04244706 -0.1446828  -0.0498443 ]\n",
      " [ 0.09239365 -0.04693325 -0.10759319]\n",
      " [-0.22375825  0.00698477  0.2641901 ]\n",
      " [-0.14059609  0.0715266   0.17309362]\n",
      " [ 0.08711779  0.0317103  -0.11257366]\n",
      " [-0.08925755  0.13109691  0.10028872]\n",
      " [ 0.12238768 -0.02056699 -0.13851574]\n",
      " [ 0.3536367   0.04717939 -0.4348395 ]\n",
      " [-0.01871852  0.17661236  0.00837395]\n",
      " [ 0.00126349  0.04183186 -0.00152584]\n",
      " [-0.21882202 -0.04628782  0.26827154]\n",
      " [-0.01125953 -0.15206374  0.01282716]\n",
      " [ 0.1181016  -0.11780249 -0.11150847]\n",
      " [-0.27929112  0.00781348  0.33394796]\n",
      " [ 0.25747532  0.00700326 -0.33367926]\n",
      " [-0.04104608 -0.03574242  0.0328456 ]\n",
      " [-0.21216272 -0.04115048  0.27945855]\n",
      " [-0.14343113  0.11491437  0.1405324 ]\n",
      " [ 0.1158802  -0.06243579 -0.11926892]\n",
      " [ 0.08583108 -0.03820036 -0.09702009]\n",
      " [ 0.18871792  0.02725462 -0.23879836]\n",
      " [ 0.22287743  0.06258046 -0.2838698 ]\n",
      " [-0.06422612  0.09785768  0.07699971]]\n",
      "ihWeightsSwapped:\n",
      "[[ 2.65321899e-02 -7.41325244e-02 -1.38492426e-02  6.83007985e-02\n",
      "  -6.21924475e-02  1.13626570e-02  4.56529520e-02 -3.34476829e-02\n",
      "   1.07460119e-01  1.01948582e-01 -5.10007329e-02 -5.50385043e-02\n",
      "   1.87815011e-01  5.79805449e-02  2.42204703e-02 -7.34286532e-02\n",
      "  -3.43908854e-02  1.75761998e-01  6.97248429e-02  8.69224817e-02\n",
      "  -9.01791360e-03 -9.04737711e-02  4.25573513e-02  4.49149013e-02\n",
      "   2.67838407e-02 -4.40769345e-02 -7.09875152e-02  1.08773254e-01\n",
      "  -1.06605381e-01  1.19626047e-02  5.68231046e-02 -3.83514836e-02\n",
      "   4.28691246e-02  3.22427824e-02  1.17213883e-01  1.94848165e-01\n",
      "  -1.25427946e-01  3.97135578e-02 -1.76375564e-02 -1.14317566e-01\n",
      "   1.43933177e-01 -1.35981396e-01 -1.31491676e-01 -3.72230075e-02\n",
      "   1.05141588e-02  1.58015057e-04  1.10773914e-01  7.58627290e-03\n",
      "   3.57860848e-02  1.38140291e-01]\n",
      " [ 1.42938900e-03 -1.03441820e-01 -1.55182285e-02  1.32641628e-01\n",
      "  -8.72495025e-02 -5.63374674e-03  5.96867912e-02  4.64150459e-02\n",
      "   1.61409602e-01  1.52610227e-01 -1.04294777e-01 -1.17056571e-01\n",
      "   2.43571863e-01  7.16267899e-02  5.16886935e-02 -1.45939112e-01\n",
      "   3.56289856e-02  2.26822063e-01  9.63726714e-02  1.36467025e-01\n",
      "   7.67289661e-03 -1.58214405e-01 -2.98035573e-02 -3.83545458e-02\n",
      "   1.04894482e-01  3.57041471e-02 -9.86089837e-03  1.33959711e-01\n",
      "  -1.59989640e-01  5.59353419e-02  6.79991618e-02 -8.98311660e-02\n",
      "   8.34777579e-02 -3.78166325e-02  1.91273727e-02  2.43847549e-01\n",
      "  -1.58359632e-01  1.31808417e-02  6.10362031e-02 -4.84367311e-02\n",
      "   1.80928379e-01 -1.95280477e-01 -1.48651138e-01 -4.20435369e-02\n",
      "   7.29950964e-02 -8.29235092e-02  1.34462893e-01  5.69431111e-02\n",
      "  -2.73004193e-02  1.60073757e-01]\n",
      " [ 6.56353086e-02  1.69708818e-01  5.43398894e-02 -2.00393364e-01\n",
      "   1.34827077e-01  4.58688885e-02 -7.58372545e-02 -1.24149419e-01\n",
      "  -2.36696482e-01 -2.18616590e-01  1.72293156e-01  1.95316389e-01\n",
      "  -3.43679488e-01 -8.71943533e-02 -1.07056066e-01  2.19214112e-01\n",
      "  -1.22546449e-01 -3.24624568e-01 -1.59246817e-01 -2.18335062e-01\n",
      "  -3.55129428e-02  2.30794549e-01  1.39166504e-01  1.51438341e-01\n",
      "  -1.99203879e-01 -1.16685368e-01 -1.19318672e-01 -2.10846707e-01\n",
      "   2.31701508e-01 -1.14509992e-01 -9.88079309e-02  1.69514239e-01\n",
      "  -1.34374902e-01  1.46377087e-01  1.00953750e-01 -3.47661048e-01\n",
      "   2.28541926e-01  1.04227532e-02 -1.60884202e-01 -6.93185776e-02\n",
      "  -2.73605943e-01  2.76869655e-01  2.33847171e-01  2.33789627e-02\n",
      "  -1.36291116e-01  1.73954725e-01 -2.06520885e-01 -1.01214521e-01\n",
      "   1.13526054e-01 -2.41151571e-01]\n",
      " [ 1.90570336e-02  9.77945626e-02  2.68851630e-02 -1.12989150e-01\n",
      "   7.62513801e-02  2.30688136e-02 -5.49575351e-02 -4.53119650e-02\n",
      "  -1.30873427e-01 -1.28597617e-01  9.14768279e-02  1.05750963e-01\n",
      "  -2.06662238e-01 -5.81765212e-02 -6.50785044e-02  1.17937423e-01\n",
      "  -4.48198356e-02 -1.83490619e-01 -9.32017341e-02 -1.27039328e-01\n",
      "  -1.33899832e-02  1.29940197e-01  5.59269413e-02  6.98685348e-02\n",
      "  -1.03928246e-01 -5.59368953e-02 -4.54047620e-02 -1.14818834e-01\n",
      "   1.27627477e-01 -6.13409542e-02 -6.26425594e-02  8.92828330e-02\n",
      "  -7.72927776e-02  7.08290860e-02  4.03967947e-02 -2.17233717e-01\n",
      "   1.46761566e-01  6.47039199e-03 -6.15917034e-02 -1.42426360e-02\n",
      "  -1.62771851e-01  1.66228130e-01  1.46859989e-01  2.29747817e-02\n",
      "  -6.31868020e-02  8.48504156e-02 -1.24924839e-01 -5.78964800e-02\n",
      "   4.18019667e-02 -1.51368082e-01]]\n",
      "hoWeightsSwapped:\n",
      "[[ 0.00758743 -0.15799192  0.18358983]\n",
      " [ 0.05670098 -0.02675555  0.04477788]\n",
      " [-0.04958735  0.1890398  -0.2222285 ]\n",
      " [ 0.00614585 -0.03478646  0.05538265]\n",
      " [ 0.03184037 -0.02599399  0.03605673]\n",
      " [-0.01304379 -0.12304983  0.14361338]\n",
      " [-0.0959836   0.08875411 -0.08215179]\n",
      " [ 0.02919671  0.07586619 -0.08733588]\n",
      " [ 0.00389098  0.20926099 -0.25478807]\n",
      " [-0.01396393  0.22706784 -0.2734356 ]\n",
      " [ 0.0690124  -0.18193316  0.2026082 ]\n",
      " [ 0.04885973 -0.15095845  0.18290624]\n",
      " [ 0.03875125  0.09553671 -0.09207425]\n",
      " [ 0.03505064  0.3557313  -0.42151657]\n",
      " [ 0.06395156 -0.21339358  0.23503721]\n",
      " [-0.02713049  0.08785822 -0.11104778]\n",
      " [ 0.04266861  0.31963548 -0.3900639 ]\n",
      " [-0.10000378  0.07746013 -0.08095209]\n",
      " [-0.05100067  0.20524012 -0.24819987]\n",
      " [-0.00494615  0.1344067  -0.18147144]\n",
      " [ 0.04336906 -0.23665473  0.2526428 ]\n",
      " [-0.0199187   0.02453953 -0.02709213]\n",
      " [ 0.14785285 -0.08557427  0.09902831]\n",
      " [ 0.12881635 -0.08333867  0.08075537]\n",
      " [-0.10710254  0.07889873 -0.07184064]\n",
      " [-0.11895293  0.17050013 -0.18304852]\n",
      " [ 0.02239914  0.18884172 -0.23836301]\n",
      " [-0.1446828   0.04244706 -0.0498443 ]\n",
      " [-0.04693325  0.09239365 -0.10759319]\n",
      " [ 0.00698477 -0.22375825  0.2641901 ]\n",
      " [ 0.0715266  -0.14059609  0.17309362]\n",
      " [ 0.0317103   0.08711779 -0.11257366]\n",
      " [ 0.13109691 -0.08925755  0.10028872]\n",
      " [-0.02056699  0.12238768 -0.13851574]\n",
      " [ 0.04717939  0.3536367  -0.4348395 ]\n",
      " [ 0.17661236 -0.01871852  0.00837395]\n",
      " [ 0.04183186  0.00126349 -0.00152584]\n",
      " [-0.04628782 -0.21882202  0.26827154]\n",
      " [-0.15206374 -0.01125953  0.01282716]\n",
      " [-0.11780249  0.1181016  -0.11150847]\n",
      " [ 0.00781348 -0.27929112  0.33394796]\n",
      " [ 0.00700326  0.25747532 -0.33367926]\n",
      " [-0.03574242 -0.04104608  0.0328456 ]\n",
      " [-0.04115048 -0.21216272  0.27945855]\n",
      " [ 0.11491437 -0.14343113  0.1405324 ]\n",
      " [-0.06243579  0.1158802  -0.11926892]\n",
      " [-0.03820036  0.08583108 -0.09702009]\n",
      " [ 0.02725462  0.18871792 -0.23879836]\n",
      " [ 0.06258046  0.22287743 -0.2838698 ]\n",
      " [ 0.09785768 -0.06422612  0.07699971]]\n",
      "Accuracy with swapped weights  on 30-item test data   = 0.9667 \n",
      "Case 1 : Swap Hidden Weights Ends \n",
      "test\n",
      "Accuracy on 30-item test data   = 0.9667 \n",
      "\n",
      "End demo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nn_backprop.py\n",
    "# Python 3.x\n",
    "#data (input=output=3, hidden=5)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def loadFile(df):\n",
    "  # load a comma-delimited text file into an np matrix\n",
    "  resultList = []\n",
    "  f = open(df, 'r')\n",
    "  for line in f:\n",
    "    line = line.rstrip('\\n')  # \"1.0,2.0,3.0\"\n",
    "    sVals = line.split(',')   # [\"1.0\", \"2.0, \"3.0\"]\n",
    "    fVals = list(map(np.float32, sVals))  # [1.0, 2.0, 3.0]\n",
    "    resultList.append(fVals)  # [[1.0, 2.0, 3.0] , [4.0, 5.0, 6.0]]\n",
    "  f.close()\n",
    "  return np.asarray(resultList, dtype=np.float32)  # not necessary\n",
    "# end loadFile\n",
    "  \n",
    "def showVector(v, dec):\n",
    "  fmt = \"%.\" + str(dec) + \"f\" # like %.4f\n",
    "  for i in range(len(v)):\n",
    "    x = v[i]\n",
    "    if x >= 0.0: print(' ', end='')\n",
    "    print(fmt % x + '  ', end='')\n",
    "  print('')\n",
    "  \n",
    "def showMatrix(m, dec):\n",
    "  fmt = \"%.\" + str(dec) + \"f\" # like %.4f  \n",
    "  for i in range(len(m)):\n",
    "    for j in range(len(m[i])):\n",
    "      x = m[i,j]\n",
    "      if x >= 0.0: print(' ', end='')\n",
    "      print(fmt % x + '  ', end='')\n",
    "    print('')\n",
    "\t\n",
    "def showMatrixPartial(m, numRows, dec, indices):\n",
    "  fmt = \"%.\" + str(dec) + \"f\" # like %.4f\n",
    "  lastRow = len(m) - 1\n",
    "  width = len(str(lastRow))\n",
    "  for i in range(numRows):\n",
    "    if indices == True:\n",
    "      print(\"[\", end='')\n",
    "      print(str(i).rjust(width), end='')\n",
    "      print(\"] \", end='')\t  \n",
    "  \n",
    "    for j in range(len(m[i])):\n",
    "      x = m[i,j]\n",
    "      if x >= 0.0: print(' ', end='')\n",
    "      print(fmt % x + '  ', end='')\n",
    "    print('')\n",
    "  print(\" . . . \")\n",
    "\n",
    "  if indices == True:\n",
    "    print(\"[\", end='')\n",
    "    print(str(lastRow).rjust(width), end='')\n",
    "    print(\"] \", end='')\t  \n",
    "  for j in range(len(m[lastRow])):\n",
    "    x = m[lastRow,j]\n",
    "    if x >= 0.0: print(' ', end='')\n",
    "    print(fmt % x + '  ', end='')\n",
    "  print('')\t  \n",
    "  \n",
    "# -----\n",
    "\t\n",
    "class NeuralNetwork:\n",
    "\n",
    "  def __init__(self, numInput, numHidden, numOutput, seed):\n",
    "    self.ni = numInput\n",
    "    self.nh = numHidden\n",
    "    self.no = numOutput\n",
    "\t\n",
    "    self.iNodes = np.zeros(shape=[self.ni], dtype=np.float32)\n",
    "    self.hNodes = np.zeros(shape=[self.nh], dtype=np.float32)\n",
    "    self.oNodes = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\t\n",
    "    self.ihWeights = np.zeros(shape=[self.ni,self.nh], dtype=np.float32)\n",
    "    self.hoWeights = np.zeros(shape=[self.nh,self.no], dtype=np.float32)\n",
    "\t\n",
    "    self.hBiases = np.zeros(shape=[self.nh], dtype=np.float32)\n",
    "    self.oBiases = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\t\n",
    "    self.rnd = random.Random(seed) # allows multiple instances\n",
    "    self.initializeWeights()\n",
    " \t\n",
    "  def setWeights(self, weights):\n",
    "    if len(weights) != self.totalWeights(self.ni, self.nh, self.no):\n",
    "      print(\"Warning: len(weights) error in setWeights()\")\t\n",
    "\n",
    "    idx = 0\n",
    "    for i in range(self.ni):\n",
    "      for j in range(self.nh):\n",
    "        self.ihWeights[i,j] = weights[idx]\n",
    "        idx += 1\n",
    "\t\t\n",
    "    for j in range(self.nh):\n",
    "      self.hBiases[j] = weights[idx]\n",
    "      idx += 1\n",
    "\n",
    "    for j in range(self.nh):\n",
    "      for k in range(self.no):\n",
    "        self.hoWeights[j,k] = weights[idx]\n",
    "        idx += 1\n",
    "\t  \n",
    "    for k in range(self.no):\n",
    "      self.oBiases[k] = weights[idx]\n",
    "      idx += 1\n",
    "\t  \n",
    "  def getWeights(self):\n",
    "    tw = self.totalWeights(self.ni, self.nh, self.no)\n",
    "    result = np.zeros(shape=[tw], dtype=np.float32)\n",
    "    idx = 0  # points into result\n",
    "    \n",
    "    for i in range(self.ni):\n",
    "      for j in range(self.nh):\n",
    "        result[idx] = self.ihWeights[i,j]\n",
    "        idx += 1\n",
    "\t\t\n",
    "    for j in range(self.nh):\n",
    "      result[idx] = self.hBiases[j]\n",
    "      idx += 1\n",
    "\n",
    "    for j in range(self.nh):\n",
    "      for k in range(self.no):\n",
    "        result[idx] = self.hoWeights[j,k]\n",
    "        idx += 1\n",
    "\t  \n",
    "    for k in range(self.no):\n",
    "      result[idx] = self.oBiases[k]\n",
    "      idx += 1\n",
    "\t  \n",
    "    return result\n",
    " \t\n",
    "  def initializeWeights(self):\n",
    "    numWts = self.totalWeights(self.ni, self.nh, self.no)\n",
    "    wts = np.zeros(shape=[numWts], dtype=np.float32)\n",
    "    lo = -0.01; hi = 0.01\n",
    "    for idx in range(len(wts)):\n",
    "      wts[idx] = (hi - lo) * self.rnd.random() + lo\n",
    "    self.setWeights(wts)\n",
    "\n",
    "  def computeOutputs(self, xValues):\n",
    "    hSums = np.zeros(shape=[self.nh], dtype=np.float32)\n",
    "    oSums = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "    for i in range(self.ni):\n",
    "      self.iNodes[i] = xValues[i]\n",
    "\n",
    "    for j in range(self.nh):\n",
    "      for i in range(self.ni):\n",
    "        hSums[j] += self.iNodes[i] * self.ihWeights[i,j]\n",
    "\n",
    "    for j in range(self.nh):\n",
    "      hSums[j] += self.hBiases[j]\n",
    "\t  \n",
    "    for j in range(self.nh):\n",
    "      self.hNodes[j] = self.hypertan(hSums[j])\n",
    "\n",
    "    for k in range(self.no):\n",
    "      for j in range(self.nh):\n",
    "        oSums[k] += self.hNodes[j] * self.hoWeights[j,k]\n",
    "\n",
    "    for k in range(self.no):\n",
    "      oSums[k] += self.oBiases[k]\n",
    " \n",
    "    softOut = self.softmax(oSums)\n",
    "    for k in range(self.no):\n",
    "      self.oNodes[k] = softOut[k]\n",
    "\t  \n",
    "    result = np.zeros(shape=self.no, dtype=np.float32)\n",
    "    for k in range(self.no):\n",
    "      result[k] = self.oNodes[k]\n",
    "\t  \n",
    "    return result\n",
    "\t\n",
    "  def train(self, trainData, maxEpochs, learnRate):\n",
    "    print(\"inside train\")\n",
    "    #print(\"inside train\", self.ni)\n",
    "    #print(\"inside train\", self.nh)\n",
    "   # print(\"inside train\", self.no)\n",
    "    #print(\"inside train trainData\", trainData)\n",
    "    hoGrads = np.zeros(shape=[self.nh, self.no], dtype=np.float32)  # hidden-to-output weights gradients\n",
    "    obGrads = np.zeros(shape=[self.no], dtype=np.float32)  # output node biases gradients\n",
    "    ihGrads = np.zeros(shape=[self.ni, self.nh], dtype=np.float32)  # input-to-hidden weights gradients\n",
    "    hbGrads = np.zeros(shape=[self.nh], dtype=np.float32)  # hidden biases gradients\n",
    "\t\n",
    "    oSignals = np.zeros(shape=[self.no], dtype=np.float32)  # output signals: gradients w/o assoc. input terms\n",
    "    hSignals = np.zeros(shape=[self.nh], dtype=np.float32)  # hidden signals: gradients w/o assoc. input terms\n",
    "\n",
    "    epoch = 0\n",
    "    x_values = np.zeros(shape=[self.ni], dtype=np.float32)\n",
    "    t_values = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "    numTrainItems = len(trainData)\n",
    "    indices = np.arange(numTrainItems)  # [0, 1, 2, . . n-1]  # rnd.shuffle(v)\n",
    "\n",
    "    while epoch < maxEpochs:\n",
    "      self.rnd.shuffle(indices)  # scramble order of training items\n",
    "      for ii in range(numTrainItems):\n",
    "        idx = indices[ii]\n",
    "        #print(\"inside train idx\", idx)\n",
    "        for j in range(self.ni):\n",
    "          x_values[j] = trainData[idx, j]  # get the input values\t\n",
    "        for j in range(self.no):\n",
    "          #print(\"inside train j+self.ni\", j+self.ni)\n",
    "          t_values[j] = trainData[idx, j+self.ni]  # get the target values\n",
    "        self.computeOutputs(x_values)  # results stored internally\n",
    "\t\t\n",
    "        # 1. compute output node signals\n",
    "        for k in range(self.no):\n",
    "          derivative = (1 - self.oNodes[k]) * self.oNodes[k]  # softmax\n",
    "          oSignals[k] = derivative * (self.oNodes[k] - t_values[k])  # E=(t-o)^2 do E'=(o-t)\n",
    "\n",
    "        # 2. compute hidden-to-output weight gradients using output signals\n",
    "        for j in range(self.nh):\n",
    "          for k in range(self.no):\n",
    "            hoGrads[j, k] = oSignals[k] * self.hNodes[j]\n",
    "\t\t\t\n",
    "        # 3. compute output node bias gradients using output signals\n",
    "        for k in range(self.no):\n",
    "          obGrads[k] = oSignals[k] * 1.0  # 1.0 dummy input can be dropped\n",
    "\t\t  \n",
    "        # 4. compute hidden node signals\n",
    "        for j in range(self.nh):\n",
    "          sum = 0.0\n",
    "          for k in range(self.no):\n",
    "            sum += oSignals[k] * self.hoWeights[j,k]\n",
    "          derivative = (1 - self.hNodes[j]) * (1 + self.hNodes[j])  # tanh activation\n",
    "          hSignals[j] = derivative * sum\n",
    "\t\t \n",
    "        # 5 compute input-to-hidden weight gradients using hidden signals\n",
    "        for i in range(self.ni):\n",
    "          for j in range(self.nh):\n",
    "            ihGrads[i, j] = hSignals[j] * self.iNodes[i]\n",
    "\n",
    "        # 6. compute hidden node bias gradients using hidden signals\n",
    "        for j in range(self.nh):\n",
    "          hbGrads[j] = hSignals[j] * 1.0  # 1.0 dummy input can be dropped\n",
    "\n",
    "        # update weights and biases using the gradients\n",
    "\t\t\n",
    "        # 1. update input-to-hidden weights\n",
    "        for i in range(self.ni):\n",
    "          for j in range(self.nh):\n",
    "            delta = -1.0 * learnRate * ihGrads[i,j]\n",
    "            self.ihWeights[i, j] += delta\n",
    "\t\t\t\n",
    "        # 2. update hidden node biases\n",
    "        for j in range(self.nh):\n",
    "          delta = -1.0 * learnRate * hbGrads[j]\n",
    "          self.hBiases[j] += delta      \n",
    "\t\t  \n",
    "        # 3. update hidden-to-output weights\n",
    "        for j in range(self.nh):\n",
    "          for k in range(self.no):\n",
    "            delta = -1.0 * learnRate * hoGrads[j,k]\n",
    "            self.hoWeights[j, k] += delta\n",
    "\t\t\t\n",
    "        # 4. update output node biases\n",
    "        for k in range(self.no):\n",
    "          delta = -1.0 * learnRate * obGrads[k]\n",
    "          self.oBiases[k] += delta\n",
    " \t\t  \n",
    "      epoch += 1\n",
    "\t  \n",
    "      if epoch % 10 == 0:\n",
    "        mse = self.meanSquaredError(trainData)\n",
    "        print(\"epoch = \" + str(epoch) + \" ms error = %0.4f \" % mse)\n",
    "    # end while\n",
    "    \n",
    "    result = self.getWeights()\n",
    "    return result,self.hoWeights,self.ihWeights\n",
    "  # end train\n",
    "    \n",
    "  def computeOutputs_AlteredWeights(self, xValues,ihWeightsNew,hoWeightsNew):\n",
    "        hSums = np.zeros(shape=[self.nh], dtype=np.float32)\n",
    "        oSums = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "        for i in range(self.ni):\n",
    "            self.iNodes[i] = xValues[i]\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            for i in range(self.ni):\n",
    "                hSums[j] += self.iNodes[i] * ihWeightsNew[i,j]\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            hSums[j] += self.hBiases[j]\n",
    " \n",
    "        for j in range(self.nh):\n",
    "            self.hNodes[j] = self.hypertan(hSums[j])\n",
    "\n",
    "        for k in range(self.no):\n",
    "            for j in range(self.nh):\n",
    "                oSums[k] += self.hNodes[j] * hoWeightsNew[j,k]\n",
    "\n",
    "        for k in range(self.no):\n",
    "            oSums[k] += self.oBiases[k]\n",
    " \n",
    "        softOut = self.softmax(oSums)\n",
    "        for k in range(self.no):\n",
    "            self.oNodes[k] = softOut[k]\n",
    "  \n",
    "        result = np.zeros(shape=self.no, dtype=np.float32)\n",
    "        for k in range(self.no):\n",
    "            result[k] = self.oNodes[k]\n",
    " \n",
    "        return result\n",
    "\n",
    "\n",
    "  def accuracy_AlteredWeights(self, tdata, ihWeightsNew, hoWeightsNew):  # train or test data matrix\n",
    "        num_correct = 0; num_wrong = 0\n",
    "        x_values = np.zeros(shape=[self.ni], dtype=np.float32)\n",
    "        t_values = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "        for i in range(len(tdata)):  # walk thru each data item\n",
    "            for j in range(self.ni):  # peel off input values from curr data row \n",
    "                x_values[j] = tdata[i,j]\n",
    "            for j in range(self.no):  # peel off tareget values from curr data row\n",
    "                t_values[j] = tdata[i, j+self.ni]\n",
    "\n",
    "            y_values = self.computeOutputs_AlteredWeights(x_values,ihWeightsNew,hoWeightsNew)  # computed output values)\n",
    "            max_index = np.argmax(y_values)  # index of largest output value \n",
    "\n",
    "            if abs(t_values[max_index] - 1.0) < 1.0e-5:\n",
    "                num_correct += 1\n",
    "            else:\n",
    "                num_wrong += 1\n",
    "\n",
    "        return (num_correct * 1.0) / (num_correct + num_wrong)\n",
    "    \n",
    "  def accuracy(self, tdata):  # train or test data matrix\n",
    "    num_correct = 0; num_wrong = 0\n",
    "    x_values = np.zeros(shape=[self.ni], dtype=np.float32)\n",
    "    t_values = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "    for i in range(len(tdata)):  # walk thru each data item\n",
    "      for j in range(self.ni):  # peel off input values from curr data row \n",
    "        x_values[j] = tdata[i,j]\n",
    "      for j in range(self.no):  # peel off tareget values from curr data row\n",
    "        t_values[j] = tdata[i, j+self.ni]\n",
    "\n",
    "      y_values = self.computeOutputs(x_values)  # computed output values)\n",
    "      max_index = np.argmax(y_values)  # index of largest output value \n",
    "\n",
    "      if abs(t_values[max_index] - 1.0) < 1.0e-5:\n",
    "        num_correct += 1\n",
    "      else:\n",
    "        num_wrong += 1\n",
    "\n",
    "    return (num_correct * 1.0) / (num_correct + num_wrong)\n",
    "\n",
    "  def meanSquaredError(self, tdata):  # on train or test data matrix\n",
    "    sumSquaredError = 0.0\n",
    "    x_values = np.zeros(shape=[self.ni], dtype=np.float32)\n",
    "    t_values = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "    for ii in range(len(tdata)):  # walk thru each data item\n",
    "      for jj in range(self.ni):  # peel off input values from curr data row \n",
    "        x_values[jj] = tdata[ii, jj]\n",
    "      for jj in range(self.no):  # peel off tareget values from curr data row\n",
    "        t_values[jj] = tdata[ii, jj+self.ni]\n",
    "\n",
    "      y_values = self.computeOutputs(x_values)  # computed output values\n",
    "\t  \n",
    "      for j in range(self.no):\n",
    "        err = t_values[j] - y_values[j]\n",
    "        sumSquaredError += err * err  # (t-o)^2\n",
    "\t\t\n",
    "    return sumSquaredError / len(tdata)\n",
    "\n",
    "  def pairwiseswap(self,lst):\n",
    "        #print(\"in pairwiseswap\" +lst)\n",
    "        def swap(l1):\n",
    "            #print(\"in swap\")\n",
    "            res = []\n",
    "            #print(\"l1 len\", len(l1))\n",
    "            for i in range(0,len(l1)-1,2):\n",
    "                res.append(l1[i+1])\n",
    "                res.append(l1[i])\n",
    "            #print(\"res\", res)\n",
    "            return res\n",
    "\n",
    "        res = []\n",
    "        if len(lst)%2==0:\n",
    "            #print(\"ev\")\n",
    "            res = swap(lst)            \n",
    "        else:\n",
    "            #print(\"od\")\n",
    "            res = swap(lst)\n",
    "            res.append(lst[len(lst)-1])\n",
    "        return res\n",
    "    \n",
    "  def pairwiseswap1_reduced(self, lst):\n",
    "        #print(\"in pairwiseswap\" +lst)\n",
    "        def swap(l1):\n",
    "            #print(\"in swap\")\n",
    "            res = []\n",
    "            swapOnce = False\n",
    "            #print(\"l1 len\", len(l1))\n",
    "            for i in range(0,len(l1)-1,2):\n",
    "                #print(\"i=\",i)\n",
    "                #print(\"swapOnce=\",swapOnce)\n",
    "                if(i==0 and swapOnce == False):\n",
    "                    swapOnce = True\n",
    "                    res.append(l1[i+1])\n",
    "                    res.append(l1[i])\n",
    "                else :\n",
    "                    res.append(l1[i])\n",
    "                    res.append(l1[i+1])\n",
    "            #print(\"res\", res)\n",
    "            return res\n",
    "\n",
    "        res = []\n",
    "        if len(lst)%2==0:\n",
    "            #print(\"ev\")\n",
    "            res = swap(lst)            \n",
    "        else:\n",
    "            #print(\"od\")\n",
    "            res = swap(lst)\n",
    "            res.append(lst[len(lst)-1])\n",
    "        return res       \n",
    "  \n",
    "  def pairwiseswap2_all(lst):\n",
    "        #print(\"in pairwiseswap\" +lst)\n",
    "        def swap(l1):\n",
    "            #print(\"in swap\")\n",
    "            res = []\n",
    "            swapOnce = False\n",
    "            #print(\"l1 len\", len(l1))\n",
    "            if(len(l1) <=3) :\n",
    "                for i in range(0,len(l1)-1,2):\n",
    "                    print(\"i=\",i)\n",
    "                    print(\"swapOnce=\",swapOnce)\n",
    "                    if(i==0 and swapOnce == False):\n",
    "                        swapOnce = True\n",
    "                        res.append(l1[i+1])\n",
    "                        res.append(l1[i])\n",
    "                    else :\n",
    "                        res.append(l1[i])\n",
    "                        res.append(l1[i+1])\n",
    "            else :\n",
    "                for i in range(0,len(l1)-1,2):\n",
    "                    print(\"i=\",i)\n",
    "                    print(\"swapOnce=\",swapOnce)\n",
    "                    if(i==2 and swapOnce == False):\n",
    "                        swapOnce = True\n",
    "                        res.append(l1[i+1])\n",
    "                        res.append(l1[i])\n",
    "                    else :\n",
    "                        res.append(l1[i])\n",
    "                        res.append(l1[i+1])\n",
    "            #print(\"res\", res)\n",
    "            return res\n",
    "\n",
    "        res = []\n",
    "        if len(lst)%2==0:\n",
    "            #print(\"ev\")\n",
    "            res = swap(lst)            \n",
    "        else:\n",
    "            #print(\"od\")\n",
    "            res = swap(lst)\n",
    "            res.append(lst[len(lst)-1])\n",
    "        return res\n",
    "    \n",
    "  @staticmethod\n",
    "  def hypertan(x):\n",
    "    if x < -20.0:\n",
    "      return -1.0\n",
    "    elif x > 20.0:\n",
    "      return 1.0\n",
    "    else:\n",
    "      return math.tanh(x)\n",
    "\n",
    "  @staticmethod\t  \n",
    "  def softmax(oSums):\n",
    "    result = np.zeros(shape=[len(oSums)], dtype=np.float32)\n",
    "    m = max(oSums)\n",
    "    divisor = 0.0\n",
    "    for k in range(len(oSums)):\n",
    "       divisor += math.exp(oSums[k] - m)\n",
    "    for k in range(len(result)):\n",
    "      result[k] =  math.exp(oSums[k] - m) / divisor\n",
    "    return result\n",
    "\t\n",
    "  @staticmethod\n",
    "  def totalWeights(nInput, nHidden, nOutput):\n",
    "   tw = (nInput * nHidden) + (nHidden * nOutput) + nHidden + nOutput\n",
    "   return tw\n",
    "\n",
    "# end class NeuralNetwork\n",
    "\n",
    "def main():\n",
    "  print(\"\\nBegin NN back-propagation demo \\n\")\n",
    "  pv = sys.version\n",
    "  npv = np.version.version \n",
    "  print(\"Using Python version \" + str(pv) +\n",
    "    \"\\n and NumPy version \"  + str(npv))\n",
    "  \n",
    "  numInput = 4# 3\n",
    "  numHidden = 50#5\n",
    "  numOutput = 3 #3\n",
    "  print(\"\\nCreating a %d-%d-%d neural network \" %\n",
    "    (numInput, numHidden, numOutput) )\n",
    "  nn = NeuralNetwork(numInput, numHidden, numOutput, seed=3)\n",
    "  \n",
    "  print(\"\\nLoading Iris training and test data \")\n",
    "  trainDataPath = \"irisTrainData.txt\" #\"irisTrainDataEven.txt\"#\"irisTrainData.txt\" #irisTrainDataNew2\n",
    "  trainDataMatrix = loadFile(trainDataPath)\n",
    "  print(\"\\nTest data: \")\n",
    "  showMatrixPartial(trainDataMatrix, 4, 1, True)\n",
    "  testDataPath = \"irisTestData.txt\"# \"irisTestDataEven.txt\"#\"irisTestData.txt\" #irisTestDataNew2\n",
    "  testDataMatrix = loadFile(testDataPath)\n",
    "  \n",
    "  maxEpochs = 50\n",
    "  learnRate = 0.01\n",
    "  print(\"\\nSetting maxEpochs = \" + str(maxEpochs))\n",
    "  print(\"Setting learning rate = %0.3f \" % learnRate)\n",
    "  print(\"\\nStarting training\")\n",
    "  res,hoW, ihW  =  nn.train(trainDataMatrix, maxEpochs, learnRate)\n",
    "  print(\"Training complete\")\n",
    "  print(\"res sh\",res.shape)\n",
    "  \n",
    "  print(\"ihW sh\",ihW.shape)\n",
    "  print(\"hoW sh\",hoW.shape)\n",
    "  #print(\"res\",res)\n",
    "  \n",
    "  print(\"ihW\",ihW)\n",
    "  print(\"hoW\",hoW)\n",
    "\n",
    "\n",
    "  accTrain = nn.accuracy(trainDataMatrix)\n",
    "  accTest = nn.accuracy(testDataMatrix)\n",
    "\n",
    "  print(\"\\nAccuracy on 120-item train data = %0.4f \" % accTrain)\n",
    "  print(\"Accuracy on 30-item test data   = %0.4f \" % accTest)\n",
    "\n",
    "  print(\"\\nEnd demo \\n\")\n",
    "  \n",
    "  print(\"ihWeights:\")  \n",
    "  #print(ihW)\n",
    "  print(\"hoWeights:\")  \n",
    "  #print(hoW)\n",
    "  \n",
    "\n",
    "\n",
    "  print(\"Case 1 : Sign Flip Starts \")\n",
    "  #a=np.array(hoW)\n",
    "  hoWeightsSignChanged = -hoW\n",
    "  #b=np.array(ihW)\n",
    "  ihWeightsSignChanged = -ihW\n",
    "  print(\"ihWeightsSignChanged:\")\n",
    "  print(ihWeightsSignChanged)\n",
    "  print(\"hoWeightsSignChanged:\")\n",
    "  print(hoWeightsSignChanged)\n",
    "  \n",
    "  #tbc\n",
    "  \n",
    "  accTrain_SignFlip = nn.accuracy_AlteredWeights(trainDataMatrix,ihWeightsSignChanged,hoWeightsSignChanged)\n",
    "  accTest_SignFlip = nn.accuracy_AlteredWeights(testDataMatrix,ihWeightsSignChanged,hoWeightsSignChanged)\n",
    "\n",
    "  \n",
    "  #print(\"\\nAccuracy with  SignFlip  on 120-item train data = %0.4f \" % accTrain_SignFlip)\n",
    "  print(\"Accuracy with SignFlip  on 30-item test data   = %0.4f \" % accTest_SignFlip)\n",
    "  print(\"Case 1 : Sign Flip Ends \")\n",
    "  \n",
    "  \n",
    "  print(\"Case 2 : Swap Hidden Weights Starts \")\n",
    "  #a=np.array(hoW)\n",
    "  \n",
    "  ihWeightsSwapped = []\n",
    "  b = ihW\n",
    "  print(\"b==ihW=\",b)\n",
    "  for k in range(len(b)): \n",
    "      ihWeightsSwapped.append(nn.pairwiseswap(b[k]))\n",
    "      #ihWeightsSwapped.append(nn.pairwiseswap1_reduced(b[k]))\n",
    "      \n",
    "    \n",
    "    \n",
    "  hoWeightsSwapped = []\n",
    "  a = hoW\n",
    "  print(\"a==hoW=\",a)\n",
    "  for k in range(len(a)):  \n",
    "      hoWeightsSwapped.append(nn.pairwiseswap(a[k]))\n",
    "      #hoWeightsSwapped.append(nn.pairwiseswap1_reduced(a[k]))\n",
    "\n",
    "  \n",
    "  \n",
    "    \n",
    "  ihWeightsSwapped = np.array(ihWeightsSwapped)\n",
    "  hoWeightsSwapped = np.array(hoWeightsSwapped)\n",
    "  print(\"ihWeightsSwapped:\")\n",
    "  print(ihWeightsSwapped)  \n",
    "\n",
    "  print(\"hoWeightsSwapped:\")\n",
    "  print(hoWeightsSwapped)\n",
    " \n",
    "  #tbc\n",
    "  \n",
    "  accTrain_WeightsSwap = nn.accuracy_AlteredWeights(trainDataMatrix,ihWeightsSwapped,hoWeightsSwapped)\n",
    "  accTest_WeightsSwap = nn.accuracy_AlteredWeights(testDataMatrix,ihWeightsSwapped,hoWeightsSwapped)\n",
    "\n",
    "  \n",
    "  #print(\"\\nAccuracy with  swapped weights  on 120-item train data = %0.4f \" % accTrain_SignFlip)\n",
    "  print(\"Accuracy with swapped weights  on 30-item test data   = %0.4f \" % accTest_SignFlip)\n",
    "  \n",
    "  print(\"Case 1 : Swap Hidden Weights Ends \")\n",
    "  \n",
    "  print(\"test\")\n",
    "  accTrain_1 = nn.accuracy_AlteredWeights(trainDataMatrix,ihW,hoW)\n",
    "  accTest_1 = nn.accuracy_AlteredWeights(testDataMatrix,ihW,hoW)\n",
    "  #print(\"\\nAccuracy on 120-item train data = %0.4f \" % accTrain_1)\n",
    "  print(\"Accuracy on 30-item test data   = %0.4f \" % accTest_1)\n",
    "    \n",
    "  '''\n",
    "  print(\"for noisy data\")\n",
    "\n",
    "  mu, sigma = 0, 0.01 \n",
    "  # creating a noise with the same dimension as the dataset (2,2) \n",
    "  noise = np.random.normal(mu, sigma, [30,7]) \n",
    "  print(noise)\n",
    "\n",
    " \n",
    "  clean_signal = testDataMatrix\n",
    "  signal = clean_signal + noise\n",
    "  print(signal)\n",
    "  testmatrixWithNoise = signal\n",
    "  #print(\"\\nAccuracy on 120-item train data = %0.4f \" % accTrain_1)\n",
    "  accTest_2 = nn.accuracy(testmatrixWithNoise)\n",
    "  print(\"Accuracy on 30-item noisy test data   = %0.4f \" % accTest_2)\n",
    "  '''\n",
    "  print(\"\\nEnd demo \\n\")\n",
    "   \n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "\n",
    "# end script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test swap\n",
    "def pairwiseswap1(self,lst):\n",
    "        def swap(l1):\n",
    "            print(\"swap\")\n",
    "            print(\"l1\")\n",
    "            res = []\n",
    "            for i in range(0,len(l1)-1,2):\n",
    "                res.append(l1[i+1])\n",
    "                res.append(l1[i])\n",
    "            return res\n",
    "\n",
    "        res = []\n",
    "        if len(lst)%2==0:\n",
    "            print(\"in ev\")\n",
    "            res = swap(lst)\n",
    "        else:\n",
    "            res = swap(lst)\n",
    "            res.append(lst[len(lst)-1])\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseswap1_reduced(self, lst):\n",
    "        #print(\"in pairwiseswap\" +lst)\n",
    "        def swap(l1):\n",
    "            #print(\"in swap\")\n",
    "            res = []\n",
    "            swapOnce = False\n",
    "            #print(\"l1 len\", len(l1))\n",
    "            for i in range(0,len(l1)-1,2):\n",
    "                #print(\"i=\",i)\n",
    "                #print(\"swapOnce=\",swapOnce)\n",
    "                if(i==0 and swapOnce == False):\n",
    "                    swapOnce = True\n",
    "                    res.append(l1[i+1])\n",
    "                    res.append(l1[i])\n",
    "                else :\n",
    "                    res.append(l1[i])\n",
    "                    res.append(l1[i+1])\n",
    "            #print(\"res\", res)\n",
    "            return res\n",
    "\n",
    "        res = []\n",
    "        if len(lst)%2==0:\n",
    "            #print(\"ev\")\n",
    "            res = swap(lst)            \n",
    "        else:\n",
    "            #print(\"od\")\n",
    "            res = swap(lst)\n",
    "            res.append(lst[len(lst)-1])\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseswap2_reduced(lst):\n",
    "        #print(\"in pairwiseswap\" +lst)\n",
    "        def swap(l1):\n",
    "            #print(\"in swap\")\n",
    "            res = []\n",
    "            swapOnce = False\n",
    "            #print(\"l1 len\", len(l1))\n",
    "            if(len(l1) <=3) :\n",
    "                for i in range(0,len(l1)-1,2):\n",
    "                    print(\"i=\",i)\n",
    "                    print(\"swapOnce=\",swapOnce)\n",
    "                    if(i==0 and swapOnce == False):\n",
    "                        swapOnce = True\n",
    "                        res.append(l1[i+1])\n",
    "                        res.append(l1[i])\n",
    "                    else :\n",
    "                        res.append(l1[i])\n",
    "                        res.append(l1[i+1])\n",
    "            else :\n",
    "                for i in range(0,len(l1)-1,2):\n",
    "                    print(\"i=\",i)\n",
    "                    print(\"swapOnce=\",swapOnce)\n",
    "                    if(i==2 and swapOnce == False):\n",
    "                        swapOnce = True\n",
    "                        res.append(l1[i+1])\n",
    "                        res.append(l1[i])\n",
    "                    else :\n",
    "                        res.append(l1[i])\n",
    "                        res.append(l1[i+1])\n",
    "            #print(\"res\", res)\n",
    "            return res\n",
    "\n",
    "        res = []\n",
    "        if len(lst)%2==0:\n",
    "            #print(\"ev\")\n",
    "            res = swap(lst)            \n",
    "        else:\n",
    "            #print(\"od\")\n",
    "            res = swap(lst)\n",
    "            res.append(lst[len(lst)-1])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseswapToroidal(lst):\n",
    "        def swap(l1):\n",
    "            print(\"swap\")\n",
    "            print(\"l1\")\n",
    "            res = []\n",
    "            print(len(l1))\n",
    "            for i in range(0,len(l1)):\n",
    "                print(i)\n",
    "                \n",
    "                if i == len(l1)-1:\n",
    "                    res.append(l1[0])\n",
    "                else :\n",
    "                    res.append(l1[i+1])\n",
    "            return res\n",
    "\n",
    "        \n",
    "        res = []\n",
    "        res = swap(lst)\n",
    "        '''\n",
    "        if len(lst)%2==0:\n",
    "            print(\"in ev\")\n",
    "            res = swap(lst)\n",
    "        else:\n",
    "            res = swap(lst)\n",
    "            res.append(lst[len(lst)-1])\n",
    "        '''\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c=  [[ 1.0766397, -0.11083151, -1.345182, 1.055, 2.55],[11,15,13,14,12]]\n",
    "c= [[ 1.411012,    2.1886458,  -1.6560197,   2.090276,    0.89395714,],\n",
    " [-0.6751054,  -0.99360114,  0.7654133,  -0.9368092,  -1.0570005 ],\n",
    " [-1.6931396 , -2.4050577,   1.9510872,  -2.3446977,  -0.5585038 ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= [[ 1.0766397,  -0.11083151, -1.345182  ],\n",
    " [ 1.2192099,   0.26164526, -1.8310475 ],\n",
    " [-0.93926555, -0.48345995,  1.7738097 ],\n",
    " [ 0.8293996,   0.74785477, -1.8291305 ],\n",
    " [ 2.39011,   -2.4308527,  -0.4801488 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in for 0\n",
      "ck [1.411012, 2.1886458, -1.6560197, 2.090276, 0.89395714]\n",
      "typeck <class 'list'>\n",
      "swap\n",
      "l1\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "in for 1\n",
      "ck [-0.6751054, -0.99360114, 0.7654133, -0.9368092, -1.0570005]\n",
      "typeck <class 'list'>\n",
      "swap\n",
      "l1\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "in for 2\n",
      "ck [-1.6931396, -2.4050577, 1.9510872, -2.3446977, -0.5585038]\n",
      "typeck <class 'list'>\n",
      "swap\n",
      "l1\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "[[2.1886458, -1.6560197, 2.090276, 0.89395714, 1.411012], [-0.99360114, 0.7654133, -0.9368092, -1.0570005, -0.6751054], [-2.4050577, 1.9510872, -2.3446977, -0.5585038, -1.6931396]]\n"
     ]
    }
   ],
   "source": [
    "nSwapped = []\n",
    "for k in range(len(c)):    \n",
    "      print(\"in for\", k)\n",
    "      print(\"ck\",c[k])\n",
    "      print(\"typeck\",type(c[k]))\n",
    "      nSwapped.append(pairwiseswapToroidal(c[k]))\n",
    "print(nSwapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in for 0\n",
      "ck [1.0766397, -0.11083151, -1.345182]\n",
      "typeck <class 'list'>\n",
      "i= 0\n",
      "swapOnce= False\n",
      "in for 1\n",
      "ck [1.2192099, 0.26164526, -1.8310475]\n",
      "typeck <class 'list'>\n",
      "i= 0\n",
      "swapOnce= False\n",
      "in for 2\n",
      "ck [-0.93926555, -0.48345995, 1.7738097]\n",
      "typeck <class 'list'>\n",
      "i= 0\n",
      "swapOnce= False\n",
      "in for 3\n",
      "ck [0.8293996, 0.74785477, -1.8291305]\n",
      "typeck <class 'list'>\n",
      "i= 0\n",
      "swapOnce= False\n",
      "in for 4\n",
      "ck [2.39011, -2.4308527, -0.4801488]\n",
      "typeck <class 'list'>\n",
      "i= 0\n",
      "swapOnce= False\n",
      "[[-0.11083151, 1.0766397, -1.345182], [0.26164526, 1.2192099, -1.8310475], [-0.48345995, -0.93926555, 1.7738097], [0.74785477, 0.8293996, -1.8291305], [-2.4308527, 2.39011, -0.4801488]]\n"
     ]
    }
   ],
   "source": [
    "nSwapped = []\n",
    "for k in range(len(c)):    \n",
    "      print(\"in for\", k)\n",
    "      print(\"ck\",c[k])\n",
    "      print(\"typeck\",type(c[k]))\n",
    "      nSwapped.append(pairwiseswap2_reduced(c[k]))\n",
    "print(nSwapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.  3.5 1.3 0.3 1.  0.  0. ]\n",
      " [4.5 2.3 1.3 0.3 1.  0.  0. ]\n",
      " [4.4 3.2 1.3 0.2 1.  0.  0. ]\n",
      " [5.  3.5 1.6 0.6 1.  0.  0. ]\n",
      " [5.1 3.8 1.9 0.4 1.  0.  0. ]\n",
      " [4.8 3.  1.4 0.3 1.  0.  0. ]\n",
      " [5.1 3.8 1.6 0.2 1.  0.  0. ]\n",
      " [4.6 3.2 1.4 0.2 1.  0.  0. ]\n",
      " [5.3 3.7 1.5 0.2 1.  0.  0. ]\n",
      " [5.  3.3 1.4 0.2 1.  0.  0. ]\n",
      " [5.5 2.6 4.4 1.2 0.  1.  0. ]\n",
      " [6.1 3.  4.6 1.4 0.  1.  0. ]\n",
      " [5.8 2.6 4.  1.2 0.  1.  0. ]\n",
      " [5.  2.3 3.3 1.  0.  1.  0. ]\n",
      " [5.6 2.7 4.2 1.3 0.  1.  0. ]\n",
      " [5.7 3.  4.2 1.2 0.  1.  0. ]\n",
      " [5.7 2.9 4.2 1.3 0.  1.  0. ]\n",
      " [6.2 2.9 4.3 1.3 0.  1.  0. ]\n",
      " [5.1 2.5 3.  1.1 0.  1.  0. ]\n",
      " [5.7 2.8 4.1 1.3 0.  1.  0. ]\n",
      " [6.7 3.1 5.6 2.4 0.  0.  1. ]\n",
      " [6.9 3.1 5.1 2.3 0.  0.  1. ]\n",
      " [5.8 2.7 5.1 1.9 0.  0.  1. ]\n",
      " [6.8 3.2 5.9 2.3 0.  0.  1. ]\n",
      " [6.7 3.3 5.7 2.5 0.  0.  1. ]\n",
      " [6.7 3.  5.2 2.3 0.  0.  1. ]\n",
      " [6.3 2.5 5.  1.9 0.  0.  1. ]\n",
      " [6.5 3.  5.2 2.  0.  0.  1. ]\n",
      " [6.2 3.4 5.4 2.3 0.  0.  1. ]\n",
      " [5.9 3.  5.1 1.8 0.  0.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "testDataPath = \"irisTestData.txt\"# \"irisTestDataEven.txt\"#\"irisTestData.txt\" #irisTestDataNew2\n",
    "testDataMatrix = loadFile(testDataPath)\n",
    "\n",
    "print(testDataMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.10608025e-03  1.84413429e-03  1.31598109e-02  1.73151022e-02]\n",
      " [-5.67819384e-03 -7.50446057e-03 -1.16847250e-02  1.54403663e-03]\n",
      " [-5.97400136e-03  6.32999826e-03  2.03457692e-02 -2.54091849e-02]\n",
      " [ 6.42280429e-03 -2.38884840e-02 -3.38927966e-03  6.04919322e-03]\n",
      " [ 2.82603003e-04  2.47375050e-02  2.83253113e-03  1.00523297e-02]\n",
      " [-4.46780047e-03  1.57111366e-03  6.56893462e-03 -7.30275331e-03]\n",
      " [ 1.11352047e-02 -7.82705591e-03  2.57701095e-03 -1.26100424e-02]\n",
      " [ 2.10189850e-02  1.09768634e-02 -5.02817788e-03  1.48963966e-03]\n",
      " [-2.58464511e-02 -1.52710936e-02  1.88821988e-03 -4.15738283e-03]\n",
      " [ 6.56333270e-03  2.74261592e-03 -1.30563603e-02  4.44921738e-03]\n",
      " [-6.24348480e-03  9.85592213e-03 -1.50994056e-03 -7.57522569e-03]\n",
      " [ 4.46807450e-03 -6.94555616e-03  1.73961828e-02 -1.29797160e-02]\n",
      " [ 2.22219293e-02  3.69433080e-03 -9.30910873e-03 -1.77035871e-03]\n",
      " [ 3.93859007e-03  6.39946647e-03 -3.83087225e-03  2.09190721e-02]\n",
      " [ 1.20571539e-03  2.49329756e-02 -7.67385829e-03  1.63241505e-02]\n",
      " [ 1.35608849e-02 -1.42937240e-03  3.17413656e-03 -1.10141311e-02]\n",
      " [-2.60799267e-05 -1.15530008e-02  1.21587410e-02 -1.13880974e-02]\n",
      " [-7.43099731e-04  5.36726639e-03 -2.64602661e-03  1.81884076e-03]\n",
      " [-1.42821765e-02  2.37467878e-03 -7.61362771e-04 -3.09447684e-03]\n",
      " [-6.78137336e-04 -4.55426658e-03 -6.99185985e-04  2.58455774e-03]\n",
      " [-1.19970802e-02  2.23238574e-02 -2.00051757e-04  6.16066754e-03]\n",
      " [-9.71665851e-03 -1.06538430e-02 -6.95238357e-03 -2.30822288e-03]\n",
      " [ 1.39905322e-02 -4.52610937e-03  5.46517736e-03 -4.08694058e-03]\n",
      " [ 6.67955837e-03  5.91092358e-04 -8.71629752e-03  1.17445314e-04]\n",
      " [ 5.15759419e-03  1.69105340e-02 -2.03746082e-03 -2.52434262e-03]\n",
      " [-2.68692282e-02 -6.29678160e-03  4.75932446e-04  2.06426834e-02]\n",
      " [-4.54024301e-03 -3.22797419e-03  1.46040166e-02 -2.41846246e-03]\n",
      " [ 9.62195670e-04 -1.50784355e-02  8.00536812e-03  1.82647454e-02]\n",
      " [ 2.37899404e-03  4.61566236e-03 -4.01995022e-03  1.99034660e-02]\n",
      " [-4.54682379e-03 -2.42304334e-03  1.01217201e-02 -1.95381605e-02]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (30,7) (30,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-36d305b7f04e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \"\"\"\n\u001b[0;32m     12\u001b[0m \u001b[0mclean_signal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestDataMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0msignal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_signal\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (30,7) (30,4) "
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "mu, sigma = 0, 0.01 \n",
    "# creating a noise with the same dimension as the dataset (2,2) \n",
    "noise = np.random.normal(mu, sigma, [30,4]) \n",
    "print(noise)\n",
    "\n",
    "\"\"\"\n",
    "print output: \n",
    "array([[-0.11114313,  0.25927152],\n",
    "       [ 0.06701506, -0.09364186]])\n",
    "\"\"\"\n",
    "clean_signal = testDataMatrix\n",
    "signal = clean_signal + noise\n",
    "print(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7ddecb955b34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    " accTest = nn.accuracy(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
